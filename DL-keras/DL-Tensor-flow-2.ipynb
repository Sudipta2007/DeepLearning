{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "#### Note: A tensor is a container for data; almost always  numerical data. So, it's a container of numbers.\n",
    "#### e.g. Matrices: 2D tensors\n",
    "### Scalars (0D tensors): A tensor that contains only one number is called a scalar (or scalar tensor, or 0D tensor). \n",
    "#### In Numpy, a float32 or float64 number is a scalar tensor (or scalar array); a scalar tensor has 0 axes (ndim == 0). The number of axes of a tensor is also called rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector (1D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 15])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 15])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrics (2D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 17, 2, 34, 10],\n",
    "             [2, 32, 45, 1, 0],\n",
    "             [8, 70, 3, 13, 91]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D tensors\n",
    "#### If you pack matrics in a new array, you obtain a 3D tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[2, 3, 4, 5, 6],\n",
    "              [0, 1, 2, 1, 4],\n",
    "             [2, 10, 4, 12, 9]],\n",
    "              [[4, 3, 12, 9, 1],\n",
    "              [2, 1, 3, 2, 10],\n",
    "              [12, 13, 10, 9, 8]],\n",
    "             [[1, 2, 3, 4, 9],\n",
    "             [21, 20, 10, 5, 9],\n",
    "             [10, 9, 8, 10, 9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, MNIST dataset is a 3D tensor of 8-bit integers. The training dataset is an array of 60,000 matrices of (28 x 28) integers. Each such matrix is a grayscale image, with coefficients between 0 and 255.\n",
    "#### Display one such Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[3]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors in Numpy\n",
    "#### Selecting specific elements in a tensor is called tensor slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Equivalent to\n",
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select 14x14 pixels in the bottom-right corner of all Images\n",
    "my_slices = train_images[:, 14:, 14:]\n",
    "my_slices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crop the images to patched 14x14 pixels in the middle\n",
    "my_slices = train_images[:, 7:-7, 7:-7]\n",
    "my_slices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation of Data Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one batch of MNIST digits, with batch size 64:\n",
    "batch = train_images[:64] # so next batch:- # batch = train_images[64:128]\n",
    "batch.shape               # nth batch: batch = train_images[64*n: 64*(n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real world examples of data tensors\n",
    "1. Vector data -- 2D tensors of shape (samples, features)\n",
    "2. Timeseries data or sequence data -- 3D tensors of shape (samples, timesteps, features)\n",
    "3. Images -- 4D tensors (samples, height, width, channes) or (samples, channels, height, width)\n",
    "4. Video -- 5D tensors (samples, frames, height, width, channels)\n",
    "#### Examples:\n",
    "##### Vector data: Dataset of people -- where we consider each person's age, height, and weight. So each person can be described by 3 values (features), and thus the entire dataset of 10,000 people can be stored in a 2D tensor of shape (10000, 3).\n",
    "##### Timeseries or sequence data: A dataset of stock price -- Consider every minute we store the current price, highest and lowest prices of last minute. Thus every minute is encoded as a 3D vector, and entire day (390 minutes) of trading encoded as a 2D tensor of shape (390, 3), and 250 days data can be stored in a 3D tensor of shape (250, 390, 3).\n",
    "##### Image data: A batch of 128 grayscale image of size (256x256) can be stored as a 4D tensor of shape (128, 256, 256, 1), where as for color images 4D tensor shape is (128, 256, 256, 3)\n",
    "##### Video data: a 60 seconds 256x256 color video clip sampled as 4 frames per second would have 240 frames. A batch of 4 such video clips can be stored in a 5D tensor of shape (4, 240, 256, 256, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
